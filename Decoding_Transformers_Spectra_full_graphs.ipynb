{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBSBy8zghrPd6I0Z+bspFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierredantas/Decoding_Transformers_Spectra/blob/main/Decoding_Transformers_Spectra_full_graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding Transformers Spectra: A Random Matrix Theory Framework Beyond the Marchenko-Pastur Law"
      ],
      "metadata": {
        "id": "DHwlTeXZTigD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load BERT and extract original matrices"
      ],
      "metadata": {
        "id": "C3GD3gVO4mXb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tv3lvqyW2Cf"
      },
      "outputs": [],
      "source": [
        "# extract_bert_matrices.py\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertModel\n",
        "\n",
        "def extract_matrices(\n",
        "    model_name: str = \"bert-base-uncased\",\n",
        "    out_dir: str = \"bert_weights\",\n",
        "    include_bias: bool = False,\n",
        "    only_linear_like: bool = True,      # skip LayerNorm/embeddings unless they are 2-D\n",
        "    dtype: str = \"float32\",             # \"float32\" | \"float64\"\n",
        "    save_format: str = \"npy\",           # \"npy\" | \"npz\" (np.savez_compressed)\n",
        "):\n",
        "    \"\"\"\n",
        "    Extracts all weight matrices from a HuggingFace BERT and saves them with a manifest.\n",
        "    \"\"\"\n",
        "    assert save_format in {\"npy\", \"npz\"}\n",
        "    np_dtype = np.float32 if dtype == \"float32\" else np.float64\n",
        "\n",
        "    # 1) Load model on CPU, no grad\n",
        "    torch.set_grad_enabled(False)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "    model.eval()\n",
        "    model.to(\"cpu\")\n",
        "\n",
        "    out = Path(out_dir)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 2) Iterate state_dict for robustness (covers all submodules)\n",
        "    sd = model.state_dict()\n",
        "    manifest = {\n",
        "        \"model_name\": model_name,\n",
        "        \"dtype\": dtype,\n",
        "        \"include_bias\": include_bias,\n",
        "        \"only_linear_like\": only_linear_like,\n",
        "        \"files\": []\n",
        "    }\n",
        "\n",
        "    # Helper to filter which tensors to keep\n",
        "    def keep_param(key: str, tensor: torch.Tensor) -> bool:\n",
        "        # Want weights (2-D) from linear/attention/FFN; optionally biases (1-D)\n",
        "        if tensor.ndim == 2:\n",
        "            # Typically Linear weights, embedding matrices (2-D), etc.\n",
        "            if only_linear_like:\n",
        "                # Heuristics: keep common linear/attention/FFN matrices\n",
        "                names_we_like = (\n",
        "                    \"encoder.layer\", \"attention\", \"intermediate\", \"output.dense\",\n",
        "                    \"self.query\", \"self.key\", \"self.value\", \"dense\", \"pooler.dense\"\n",
        "                )\n",
        "                return any(n in key for n in names_we_like)\n",
        "            return True\n",
        "\n",
        "        if include_bias and tensor.ndim == 1:\n",
        "            # keep biases if requested\n",
        "            names_we_like = (\"bias\",)\n",
        "            return any(n in key for n in names_we_like)\n",
        "\n",
        "        return False\n",
        "\n",
        "    # 3) Save tensors and record metadata\n",
        "    for key in sorted(sd.keys()):\n",
        "        t = sd[key]\n",
        "        if not keep_param(key, t):\n",
        "            continue\n",
        "\n",
        "        arr = t.detach().cpu().to(dtype=torch.float32 if dtype == \"float32\" else torch.float64).numpy()\n",
        "\n",
        "        # Build a safe, hierarchical path\n",
        "        # Example key: \"encoder.layer.0.attention.self.query.weight\"\n",
        "        # -> encoder/layer_0/attention/self/query/weight.npy\n",
        "        parts = key.split(\".\")\n",
        "        # normalize \"layer.N\" to \"layer_N\"\n",
        "        norm_parts = []\n",
        "        for p in parts:\n",
        "            if p == \"layer\":\n",
        "                continue\n",
        "            if p.isdigit():  # the index that follows \"layer\"\n",
        "                norm_parts.append(f\"layer_{p}\")\n",
        "            else:\n",
        "                norm_parts.append(p)\n",
        "\n",
        "        # Put under base directory\n",
        "        save_dir = out.joinpath(*norm_parts[:-1])  # all but the last (usually \"weight\" or \"bias\")\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        stem = norm_parts[-1]  # \"weight\" or \"bias\"\n",
        "        ext = \".npy\" if save_format == \"npy\" else \".npz\"\n",
        "        path = save_dir / f\"{stem}{ext}\"\n",
        "\n",
        "        if save_format == \"npy\":\n",
        "            np.save(path, arr)\n",
        "        else:\n",
        "            np.savez_compressed(path, data=arr)\n",
        "\n",
        "        manifest[\"files\"].append({\n",
        "            \"name\": key,\n",
        "            \"path\": str(path.relative_to(out)),\n",
        "            \"shape\": list(arr.shape),\n",
        "            \"ndim\": arr.ndim,\n",
        "            \"dtype\": str(arr.dtype)\n",
        "        })\n",
        "\n",
        "    # 4) Also save a flat copy for embeddings if you want them explicitly grouped\n",
        "    # (Optional—comment out if you don't need a separate embeddings folder)\n",
        "    emb_dir = out / \"embeddings\"\n",
        "    emb_dir.mkdir(exist_ok=True)\n",
        "    for subkey, param in model.embeddings.state_dict().items():\n",
        "        if param.ndim == 2 or (include_bias and param.ndim == 1):\n",
        "            arr = param.detach().cpu().to(dtype=torch.float32 if dtype == \"float32\" else torch.float64).numpy()\n",
        "            fname = (subkey.replace(\".\", \"_\") + (\"_bias\" if subkey.endswith(\"bias\") else \"\") +\n",
        "                     (\".npy\" if save_format == \"npy\" else \".npz\"))\n",
        "            path = emb_dir / fname\n",
        "            if save_format == \"npy\":\n",
        "                np.save(path, arr)\n",
        "            else:\n",
        "                np.savez_compressed(path, data=arr)\n",
        "\n",
        "            manifest[\"files\"].append({\n",
        "                \"name\": f\"embeddings.{subkey}\",\n",
        "                \"path\": str(path.relative_to(out)),\n",
        "                \"shape\": list(arr.shape),\n",
        "                \"ndim\": arr.ndim,\n",
        "                \"dtype\": str(arr.dtype)\n",
        "            })\n",
        "\n",
        "    # 5) Write manifest\n",
        "    with open(out / \"manifest.json\", \"w\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    print(f\"Saved to: {out.resolve()}\")\n",
        "    print(f\"Total tensors saved: {len(manifest['files'])}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_matrices(\n",
        "        model_name=\"bert-base-uncased\",\n",
        "        out_dir=\"bert_weights\",\n",
        "        include_bias=False,\n",
        "        only_linear_like=True,\n",
        "        dtype=\"float32\",\n",
        "        save_format=\"npy\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Wn and save stats"
      ],
      "metadata": {
        "id": "QHGS-IqhPjT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Build WMP and save stats for inversion\n",
        "# =========================\n",
        "# Inputs:\n",
        "#   - bert_weights/ (from extract_bert_matrices.py)\n",
        "# Outputs:\n",
        "#   - step1_column_stats.json   (human-readable, key map)\n",
        "#   - step1_column_stats.npz    (exact np arrays of means/stds)\n",
        "#   - bert_weights_WMP/          (normalized matrices) + manifest.json\n",
        "\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime, UTC\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "WEIGHTS_DIR = \"bert_weights\"\n",
        "STATS_JSON  = \"step1_column_stats.json\"\n",
        "STATS_NPZ   = \"step1_column_stats.npz\"\n",
        "WMP_DIR      = \"bert_weights_WMP\"\n",
        "\n",
        "def _safe_key(idx: int, kind: str, name: str) -> str:\n",
        "    \"\"\"Create stable NPZ keys like '0003__mean__encoder_layer_0_attention_self_query_weight'.\"\"\"\n",
        "    base = f\"{idx:04d}__{kind}__\" + re.sub(r\"[^0-9a-zA-Z_]+\", \"_\", name)\n",
        "    base = re.sub(r\"__+\", \"__\", base).strip(\"_\")\n",
        "    return base[:200]\n",
        "\n",
        "def _load_matrix(path: Path) -> np.ndarray:\n",
        "    if path.suffix == \".npy\":\n",
        "        return np.load(path)\n",
        "    if path.suffix == \".npz\":\n",
        "        return np.load(path)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {path.suffix}\")\n",
        "\n",
        "def _save_npy(path: Path, arr: np.ndarray) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    np.save(path, arr)\n",
        "\n",
        "# ------------- Step 1: compute and save column-wise stats -------------\n",
        "weights_dir = Path(WEIGHTS_DIR)\n",
        "manifest_path = weights_dir / \"manifest.json\"\n",
        "assert manifest_path.exists(), f\"Manifest not found at {manifest_path}\"\n",
        "\n",
        "with open(manifest_path, \"r\") as f:\n",
        "    manifest = json.load(f)\n",
        "\n",
        "npz_store = {}\n",
        "stats_json = {\n",
        "    \"model_name\": manifest.get(\"model_name\", \"\"),\n",
        "    \"created_at\": datetime.now(UTC).isoformat(),\n",
        "    \"weights_dir\": str(weights_dir),\n",
        "    \"count_files\": 0,\n",
        "    \"files\": []\n",
        "}\n",
        "\n",
        "files = manifest.get(\"files\", [])\n",
        "processed = 0\n",
        "for idx, entry in enumerate(files):\n",
        "    relpath = entry.get(\"path\")\n",
        "    name    = entry.get(\"name\", relpath)\n",
        "    shape   = entry.get(\"shape\")\n",
        "\n",
        "    fpath = weights_dir / relpath\n",
        "    if not fpath.exists():\n",
        "        print(f\"[MISS] {relpath}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        W = _load_matrix(fpath)\n",
        "    except Exception as e:\n",
        "        print(f\"[LOAD-ERR] {relpath}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if W.ndim != 2:\n",
        "        continue  # only 2-D matrices\n",
        "\n",
        "    # Column-wise stats (axis=0); compute in float64 for stability\n",
        "    W = W.astype(np.float64, copy=False)\n",
        "    mu = W.mean(axis=0)          # shape (n,)\n",
        "    sd = W.std(axis=0)           # shape (n,)\n",
        "\n",
        "    mean_key = _safe_key(idx, \"mean\", name)\n",
        "    std_key  = _safe_key(idx, \"std\",  name)\n",
        "    npz_store[mean_key] = mu\n",
        "    npz_store[std_key]  = sd\n",
        "\n",
        "    stats_json[\"files\"].append({\n",
        "        \"index\": idx,\n",
        "        \"name\": name,\n",
        "        \"path\": relpath,\n",
        "        \"shape\": shape,\n",
        "        \"npz_keys\": {\"mean\": mean_key, \"std\": std_key},\n",
        "        \"summary\": {\n",
        "            \"mean_of_means\": float(mu.mean()),\n",
        "            \"mean_of_stds\": float(sd.mean()),\n",
        "            \"max_std\": float(sd.max()),\n",
        "            \"min_std\": float(sd.min())\n",
        "        }\n",
        "    })\n",
        "    processed += 1\n",
        "    if processed % 25 == 0:\n",
        "        print(f\"[STATS] Processed {processed} matrices...\")\n",
        "\n",
        "stats_json[\"count_files\"] = processed\n",
        "\n",
        "with open(STATS_JSON, \"w\") as jf:\n",
        "    json.dump(stats_json, jf, indent=2)\n",
        "np.savez_compressed(STATS_NPZ, **npz_store)\n",
        "\n",
        "print(f\"[STATS] Done. Matrices processed: {processed}\")\n",
        "print(f\"[STATS] JSON: {STATS_JSON}\")\n",
        "print(f\"[STATS] NPZ : {STATS_NPZ}\")\n",
        "\n",
        "# ------------- Step 2: build WMP=(W - 1*mu)/sd and save with manifest -------------\n",
        "out_root = Path(WMP_DIR)\n",
        "out_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# prepare WMP manifest (clone key fields)\n",
        "wmp_manifest = {\n",
        "    \"model_name\": manifest.get(\"model_name\", \"\") + \" (column-standardized)\",\n",
        "    \"dtype\": \"float64\",\n",
        "    \"include_bias\": manifest.get(\"include_bias\", False),\n",
        "    \"only_linear_like\": manifest.get(\"only_linear_like\", True),\n",
        "    \"files\": []\n",
        "}\n",
        "\n",
        "stats_npz = np.load(STATS_NPZ)\n",
        "\n",
        "saved = 0\n",
        "skipped = 0\n",
        "for entry in stats_json[\"files\"]:\n",
        "    relpath = entry[\"path\"]\n",
        "    name    = entry[\"name\"]\n",
        "    mu      = stats_npz[entry[\"npz_keys\"][\"mean\"]]  # (n,)\n",
        "    sd      = stats_npz[entry[\"npz_keys\"][\"std\"]]   # (n,)\n",
        "\n",
        "    src_path = weights_dir / relpath\n",
        "    if not src_path.exists():\n",
        "        print(f\"[MISS-WMP] {relpath}\")\n",
        "        continue\n",
        "\n",
        "    W = _load_matrix(src_path)\n",
        "    if W.ndim != 2:\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    W = W.astype(np.float64, copy=False)\n",
        "\n",
        "    # Guard zero-variance columns; they remain constant after normalization\n",
        "    safe_sd = np.where(sd == 0, 1.0, sd)\n",
        "\n",
        "    # WMP = (W - 1*mu)/sd  -> broadcast along rows (axis=0)\n",
        "    WMP = (W - mu.reshape(1, -1)) / safe_sd.reshape(1, -1)\n",
        "\n",
        "    dst_path = out_root / relpath\n",
        "    _save_npy(dst_path, WMP)\n",
        "\n",
        "    wmp_manifest[\"files\"].append({\n",
        "        \"name\": name.replace(\".weight\", \".weight_WMP\"),\n",
        "        \"path\": str(dst_path.relative_to(out_root)),\n",
        "        \"shape\": list(WMP.shape),\n",
        "        \"ndim\": 2,\n",
        "        \"dtype\": str(WMP.dtype)\n",
        "    })\n",
        "    saved += 1\n",
        "    if saved % 25 == 0:\n",
        "        print(f\"[WMP] Saved {saved} matrices...\")\n",
        "\n",
        "with open(out_root / \"manifest.json\", \"w\") as f:\n",
        "    json.dump(wmp_manifest, f, indent=2)\n",
        "\n",
        "# ------------- Quick verification on a few matrices -------------\n",
        "from itertools import islice\n",
        "\n",
        "def _check_one(relpath: str, mu: np.ndarray, sd: np.ndarray) -> float:\n",
        "    W  = _load_matrix(weights_dir / relpath).astype(np.float64)\n",
        "    WMP = _load_matrix(out_root / relpath).astype(np.float64)\n",
        "    safe_sd = np.where(sd == 0, 1.0, sd)\n",
        "    W_rec = WMP * safe_sd.reshape(1, -1) + mu.reshape(1, -1)\n",
        "    return float(np.max(np.abs(W - W_rec)))\n",
        "\n",
        "print(\"====================================================\")\n",
        "print(f\"✅ WMP saved: {saved} | Skipped (non-2D): {skipped}\")\n",
        "print(f\"Manifest written: {out_root / 'manifest.json'}\")\n",
        "\n",
        "# Pick up to 3 entries and verify round-trip reconstruction\n",
        "errs = []\n",
        "for e in islice(stats_json[\"files\"], 3):\n",
        "    rel = e[\"path\"]\n",
        "    mu  = stats_npz[e[\"npz_keys\"][\"mean\"]]\n",
        "    sd  = stats_npz[e[\"npz_keys\"][\"std\"]]\n",
        "    errs.append((rel, _check_one(rel, mu, sd)))\n",
        "for rel, err in errs:\n",
        "    print(f\"[CHECK] {rel}: max |W - (WMP*sd+mu)| = {err:.3e}\")\n",
        "print(\"====================================================\")\n"
      ],
      "metadata": {
        "id": "Qk5xFSeDY1vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 1 - Empirical PDF (ePDF) vs. conditional MPd PDF under different trimming conditions."
      ],
      "metadata": {
        "id": "oMq0TV9RDSAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mosaic plots for six parameter sets (PDFs) ---\n",
        "# Purpose: Generate mosaic plots comparing empirical and theoretical\n",
        "#          eigenvalue distributions for various matrix settings.\n",
        "# Prereq: \"bert_weights_WMP/manifest.json\" exists and contains standardized matrices.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def _load_matrix(p: Path):\n",
        "    \"\"\"Loads a NumPy matrix from a .npy or .npz file.\"\"\"\n",
        "    if p.suffix == \".npy\":  return np.load(p)\n",
        "    if p.suffix == \".npz\":  return np.load(p)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
        "\n",
        "def _mp_support(beta: float):\n",
        "    \"\"\"Calculates the Marchenko-Pastur support bounds.\"\"\"\n",
        "    r = np.sqrt(beta); return (1 - r)**2, (1 + r)**2\n",
        "\n",
        "def _mp_pdf(x, beta, a, b):\n",
        "    \"\"\"Calculates the Marchenko-Pastur PDF.\"\"\"\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    out = np.zeros_like(x)\n",
        "    m = (x >= a) & (x <= b)\n",
        "    xm = np.clip(x[m], 1e-15, None)\n",
        "    out[m] = np.sqrt((b - xm) * (xm - a)) / (2 * np.pi * beta * xm)\n",
        "    return out\n",
        "\n",
        "def _cumtrapz_np(y, x):\n",
        "    \"\"\"Performs cumulative trapezoidal integration on NumPy arrays.\"\"\"\n",
        "    dx = np.diff(x); seg = 0.5 * (y[:-1] + y[1:]) * dx\n",
        "    return np.concatenate([[0.0], np.cumsum(seg)])\n",
        "\n",
        "def _mp_cdf(x, beta, grid_points=8192):\n",
        "    \"\"\"Calculates the Marchenko-Pastur CDF using numerical integration.\"\"\"\n",
        "    a, b = _mp_support(beta)\n",
        "    t = np.linspace(0.0, 1.0, grid_points)\n",
        "    g = a + (b - a) * t * t\n",
        "    pdf = _mp_pdf(g, beta, a, b)\n",
        "    cdf_vals = _cumtrapz_np(pdf, g)\n",
        "    cdf_vals /= cdf_vals[-1]\n",
        "    return np.interp(x, g, cdf_vals, left=0.0, right=1.0)\n",
        "\n",
        "def _edge_margin(beta, m, n, trim_kind, c_tw, frac_sq, frac_rect):\n",
        "    \"\"\"Determines the trimming margin based on different rules.\"\"\"\n",
        "    a, b = _mp_support(beta); bandwidth = b - a\n",
        "    n_eff = min(m, n); is_square = (m == n)\n",
        "    tw = c_tw * (n_eff ** (-2/3)) * (1 + np.sqrt(beta))**(4/3)\n",
        "    frac = (frac_sq if is_square else frac_rect) * bandwidth\n",
        "    if trim_kind == \"tw\": return tw\n",
        "    if trim_kind == \"fraction\": return frac\n",
        "    if trim_kind == \"tw_or_fraction\": return max(tw, frac)\n",
        "    raise ValueError(\"Invalid trim_kind\")\n",
        "\n",
        "def _find_manifest_entry(manifest, target):\n",
        "    \"\"\"Finds a matrix entry in the manifest file.\"\"\"\n",
        "    for e in manifest[\"files\"]:\n",
        "        if e.get(\"name\",\"\") == target: return e\n",
        "    for e in manifest[\"files\"]:\n",
        "        if target in e.get(\"name\",\"\") or target in e.get(\"path\",\"\"): return e\n",
        "    raise ValueError(f\"Matrix '{target}' not found in manifest\")\n",
        "\n",
        "def compute_trimmed(W, TRIM_KIND, C_TW, EDGE_FRAC_SQUARE, EDGE_FRAC_RECT):\n",
        "    \"\"\"Computes trimmed eigenvalues and conditional MP distributions.\"\"\"\n",
        "    m,n = W.shape; beta = min(m,n)/max(m,n)\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2)/max(m,n); lambdas.sort()\n",
        "    a,b = _mp_support(beta)\n",
        "    delta = _edge_margin(beta,m,n,TRIM_KIND,C_TW,EDGE_FRAC_SQUARE,EDGE_FRAC_RECT)\n",
        "    L,U = a+delta, b-delta\n",
        "    if L>=U: L,U=a,b\n",
        "    mask = (lambdas>=L)&(lambdas<=U)\n",
        "    lam_trim = lambdas[mask]; N_trim = lam_trim.size\n",
        "    FL,FU = _mp_cdf([L,U], beta); den = max(FU-FL,1e-12)\n",
        "    mp_pdf_cond = lambda x: _mp_pdf(x,beta,a,b)/den\n",
        "    mp_cdf_cond = lambda x: np.clip((_mp_cdf(x,beta)-FL)/den,0,1)\n",
        "    return lam_trim, (a,b,L,U,beta), mp_pdf_cond, mp_cdf_cond, N_trim\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "WMP_DIR = \"bert_weights_WMP\"\n",
        "GRID_POINTS = 8192\n",
        "COND_GRID = 2000\n",
        "HIST_BINS = 150\n",
        "\n",
        "# Define parameter sets exactly as specified\n",
        "SETTINGS = [\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 1 — baseline\"),\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=1.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 2 — tight TW\"),\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"fraction\", c_tw=1.0, frac_sq=0.05, frac_rect=0.15, label=\"Set 3 — loose trim\"),\n",
        "    dict(name=\"embeddings.position_embeddings.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 4 — embeddings (β≈1)\"),\n",
        "    dict(name=\"embeddings.position_embeddings.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=3.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 5 — heavy relaxation\"),\n",
        "    dict(name=\"encoder.layer.11.output.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 6 — deep layer\"),\n",
        "]\n",
        "\n",
        "# Load manifest once\n",
        "man_path = Path(WMP_DIR) / \"manifest.json\"\n",
        "manifest = json.load(open(man_path))\n",
        "\n",
        "# =========================\n",
        "# MOSAIC: PDFs\n",
        "# =========================\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10,12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, cfg in zip(axes, SETTINGS):\n",
        "    entry = _find_manifest_entry(manifest, cfg[\"name\"])\n",
        "    W = _load_matrix(Path(WMP_DIR)/entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    lam_trim,(a,b,L,U,beta),mp_pdf_cond,mp_cdf_cond,N_trim = compute_trimmed(\n",
        "        W, cfg[\"trim_kind\"], cfg[\"c_tw\"], cfg[\"frac_sq\"], cfg[\"frac_rect\"]\n",
        "    )\n",
        "    x_grid = np.linspace(L,U,COND_GRID)\n",
        "    if N_trim>0:\n",
        "        ax.hist(lam_trim,bins=HIST_BINS,range=(L,U),density=True,alpha=0.5)\n",
        "    ax.plot(x_grid, mp_pdf_cond(x_grid),'r-',lw=2)\n",
        "    for v,col in [(a,\"gray\"),(b,\"gray\"),(L,\"g\"),(U,\"g\")]:\n",
        "        ax.axvline(v,color=col,linestyle=\"--\",lw=1)\n",
        "    ax.set_title(f\"{cfg['label']}\\nPDF (β={beta:.2f}, N={N_trim})\",fontsize=9)\n",
        "    ax.set_xlabel(\"λ\"); ax.set_ylabel(\"Density\"); ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_core_diag_01.pdf\", format=\"pdf\")\n",
        "\n",
        "# =========================\n",
        "# Print PARAMETERS summary for each subplot\n",
        "# =========================\n",
        "print(\"=\"*60)\n",
        "print(\"▶ PARAMETERS USED FOR MOSAIC (line=row, column=col)\")\n",
        "for i, cfg in enumerate(SETTINGS):\n",
        "    row, col = divmod(i, 3)\n",
        "    entry = _find_manifest_entry(manifest, cfg[\"name\"])\n",
        "    W = _load_matrix(Path(WMP_DIR)/entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    lam_trim,(a,b,L,U,beta),mp_pdf_cond,mp_cdf_cond,N_trim = compute_trimmed(\n",
        "        W, cfg[\"trim_kind\"], cfg[\"c_tw\"], cfg[\"frac_sq\"], cfg[\"frac_rect\"]\n",
        "    )\n",
        "    print(f\"[row {row+1}, col {col+1}] {cfg['label']}\")\n",
        "    print(f\"- Matrix name   : {cfg['name']}\")\n",
        "    print(f\"- Shape (m,n)   : {W.shape}\")\n",
        "    print(f\"- Aspect ratio β: {beta:.6f}\")\n",
        "    print(f\"- λ- , λ+       : [{a:.6f}, {b:.6f}]\")\n",
        "    print(f\"- Trimming rule : {cfg['trim_kind']} (c_TW={cfg['c_tw']}, \"\n",
        "          f\"EDGE_FRAC_SQ={cfg['frac_sq']}, EDGE_FRAC_RECT={cfg['frac_rect']})\")\n",
        "    print(f\"- Trim interval : [L,U] = [{L:.6f}, {U:.6f}]\")\n",
        "    print(f\"- Eigenvalues   : kept {N_trim}/{len(W)} after trimming\")\n",
        "    print(f\"- Histogram bins: {HIST_BINS}\")\n",
        "    print(\"-\"*40)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "t-eHRAUT4rcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 2 - Empirical CDF (eCDF) vs. conditional MPd CDF under different trimming conditions."
      ],
      "metadata": {
        "id": "OrMQ2Pw55fzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mosaic plots for six parameter sets (CDFs) ---\n",
        "# Purpose: Generate mosaic plots comparing empirical and theoretical\n",
        "#          eigenvalue distributions for various matrix settings.\n",
        "# Prereq: \"bert_weights_WMP/manifest.json\" exists and contains standardized matrices.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def _load_matrix(p: Path):\n",
        "    \"\"\"Loads a NumPy matrix from a .npy or .npz file.\"\"\"\n",
        "    if p.suffix == \".npy\":  return np.load(p)\n",
        "    if p.suffix == \".npz\":  return np.load(p)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
        "\n",
        "def _mp_support(beta: float):\n",
        "    \"\"\"Calculates the Marchenko-Pastur support bounds.\"\"\"\n",
        "    r = np.sqrt(beta); return (1 - r)**2, (1 + r)**2\n",
        "\n",
        "def _mp_pdf(x, beta, a, b):\n",
        "    \"\"\"Calculates the Marchenko-Pastur PDF.\"\"\"\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    out = np.zeros_like(x)\n",
        "    m = (x >= a) & (x <= b)\n",
        "    xm = np.clip(x[m], 1e-15, None)\n",
        "    out[m] = np.sqrt((b - xm) * (xm - a)) / (2 * np.pi * beta * xm)\n",
        "    return out\n",
        "\n",
        "def _cumtrapz_np(y, x):\n",
        "    \"\"\"Performs cumulative trapezoidal integration on NumPy arrays.\"\"\"\n",
        "    dx = np.diff(x); seg = 0.5 * (y[:-1] + y[1:]) * dx\n",
        "    return np.concatenate([[0.0], np.cumsum(seg)])\n",
        "\n",
        "def _mp_cdf(x, beta, grid_points=8192):\n",
        "    \"\"\"Calculates the Marchenko-Pastur CDF using numerical integration.\"\"\"\n",
        "    a, b = _mp_support(beta)\n",
        "    t = np.linspace(0.0, 1.0, grid_points)\n",
        "    g = a + (b - a) * t * t\n",
        "    pdf = _mp_pdf(g, beta, a, b)\n",
        "    cdf_vals = _cumtrapz_np(pdf, g)\n",
        "    cdf_vals /= cdf_vals[-1]\n",
        "    return np.interp(x, g, cdf_vals, left=0.0, right=1.0)\n",
        "\n",
        "def _edge_margin(beta, m, n, trim_kind, c_tw, frac_sq, frac_rect):\n",
        "    \"\"\"Determines the trimming margin based on different rules.\"\"\"\n",
        "    a, b = _mp_support(beta); bandwidth = b - a\n",
        "    n_eff = min(m, n); is_square = (m == n)\n",
        "    tw = c_tw * (n_eff ** (-2/3)) * (1 + np.sqrt(beta))**(4/3)\n",
        "    frac = (frac_sq if is_square else frac_rect) * bandwidth\n",
        "    if trim_kind == \"tw\": return tw\n",
        "    if trim_kind == \"fraction\": return frac\n",
        "    if trim_kind == \"tw_or_fraction\": return max(tw, frac)\n",
        "    raise ValueError(\"Invalid trim_kind\")\n",
        "\n",
        "def _find_manifest_entry(manifest, target):\n",
        "    \"\"\"Finds a matrix entry in the manifest file.\"\"\"\n",
        "    for e in manifest[\"files\"]:\n",
        "        if e.get(\"name\",\"\") == target: return e\n",
        "    for e in manifest[\"files\"]:\n",
        "        if target in e.get(\"name\",\"\") or target in e.get(\"path\",\"\"): return e\n",
        "    raise ValueError(f\"Matrix '{target}' not found in manifest\")\n",
        "\n",
        "def compute_trimmed(W, TRIM_KIND, C_TW, EDGE_FRAC_SQUARE, EDGE_FRAC_RECT):\n",
        "    \"\"\"Computes trimmed eigenvalues and conditional MP distributions.\"\"\"\n",
        "    m,n = W.shape; beta = min(m,n)/max(m,n)\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2)/max(m,n); lambdas.sort()\n",
        "    a,b = _mp_support(beta)\n",
        "    delta = _edge_margin(beta,m,n,TRIM_KIND,C_TW,EDGE_FRAC_SQUARE,EDGE_FRAC_RECT)\n",
        "    L,U = a+delta, b-delta\n",
        "    if L>=U: L,U=a,b\n",
        "    mask = (lambdas>=L)&(lambdas<=U)\n",
        "    lam_trim = lambdas[mask]; N_trim = lam_trim.size\n",
        "    FL,FU = _mp_cdf([L,U], beta); den = max(FU-FL,1e-12)\n",
        "    mp_pdf_cond = lambda x: _mp_pdf(x,beta,a,b)/den\n",
        "    mp_cdf_cond = lambda x: np.clip((_mp_cdf(x,beta)-FL)/den,0,1)\n",
        "    return lam_trim, (a,b,L,U,beta), mp_pdf_cond, mp_cdf_cond, N_trim\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "WMP_DIR = \"bert_weights_WMP\"\n",
        "GRID_POINTS = 8192\n",
        "COND_GRID = 2000\n",
        "HIST_BINS = 150\n",
        "\n",
        "# Define parameter sets exactly as specified\n",
        "SETTINGS = [\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 1 — baseline\"),\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=1.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 2 — tight TW\"),\n",
        "    dict(name=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"fraction\", c_tw=1.0, frac_sq=0.05, frac_rect=0.15, label=\"Set 3 — loose trim\"),\n",
        "    dict(name=\"embeddings.position_embeddings.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 4 — embeddings (β≈1)\"),\n",
        "    dict(name=\"embeddings.position_embeddings.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=3.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 5 — heavy relaxation\"),\n",
        "    dict(name=\"encoder.layer.11.output.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", c_tw=2.0, frac_sq=0.05, frac_rect=0.05, label=\"Set 6 — deep layer\"),\n",
        "]\n",
        "\n",
        "# Load manifest once\n",
        "man_path = Path(WMP_DIR) / \"manifest.json\"\n",
        "manifest = json.load(open(man_path))\n",
        "\n",
        "# =========================\n",
        "# MOSAIC: CDFs\n",
        "# =========================\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10,12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, cfg in zip(axes, SETTINGS):\n",
        "    entry = _find_manifest_entry(manifest, cfg[\"name\"])\n",
        "    W = _load_matrix(Path(WMP_DIR)/entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    lam_trim,(a,b,L,U,beta),mp_pdf_cond,mp_cdf_cond,N_trim = compute_trimmed(\n",
        "        W, cfg[\"trim_kind\"], cfg[\"c_tw\"], cfg[\"frac_sq\"], cfg[\"frac_rect\"]\n",
        "    )\n",
        "    x_grid = np.linspace(L,U,COND_GRID)\n",
        "    ax.plot(x_grid, mp_cdf_cond(x_grid),'r-',lw=2,label=\"MP CDF\")\n",
        "    if N_trim>0:\n",
        "        y_ecdf = np.arange(1,N_trim+1)/N_trim\n",
        "        ax.step(lam_trim,y_ecdf,where=\"post\",label=\"Empirical CDF\")\n",
        "    for v,col in [(a,\"gray\"),(b,\"gray\"),(L,\"g\"),(U,\"g\")]:\n",
        "        ax.axvline(v,color=col,linestyle=\"--\",lw=1)\n",
        "    ax.set_title(f\"{cfg['label']}\\nCDF (β={beta:.2f}, N={N_trim})\",fontsize=9)\n",
        "    ax.set_xlabel(\"λ\"); ax.set_ylabel(\"CDF\"); ax.set_ylim(0,1); ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_core_diag_02.pdf\", format=\"pdf\")\n",
        "\n",
        "# =========================\n",
        "# Print PARAMETERS summary for each subplot\n",
        "# =========================\n",
        "print(\"=\"*60)\n",
        "print(\"▶ PARAMETERS USED FOR MOSAIC (line=row, column=col)\")\n",
        "for i, cfg in enumerate(SETTINGS):\n",
        "    row, col = divmod(i, 3)\n",
        "    entry = _find_manifest_entry(manifest, cfg[\"name\"])\n",
        "    W = _load_matrix(Path(WMP_DIR)/entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    lam_trim,(a,b,L,U,beta),mp_pdf_cond,mp_cdf_cond,N_trim = compute_trimmed(\n",
        "        W, cfg[\"trim_kind\"], cfg[\"c_tw\"], cfg[\"frac_sq\"], cfg[\"frac_rect\"]\n",
        "    )\n",
        "    print(f\"[row {row+1}, col {col+1}] {cfg['label']}\")\n",
        "    print(f\"- Matrix name   : {cfg['name']}\")\n",
        "    print(f\"- Shape (m,n)   : {W.shape}\")\n",
        "    print(f\"- Aspect ratio β: {beta:.6f}\")\n",
        "    print(f\"- λ- , λ+       : [{a:.6f}, {b:.6f}]\")\n",
        "    print(f\"- Trimming rule : {cfg['trim_kind']} (c_TW={cfg['c_tw']}, \"\n",
        "          f\"EDGE_FRAC_SQ={cfg['frac_sq']}, EDGE_FRAC_RECT={cfg['frac_rect']})\")\n",
        "    print(f\"- Trim interval : [L,U] = [{L:.6f}, {U:.6f}]\")\n",
        "    print(f\"- Eigenvalues   : kept {N_trim}/{len(W)} after trimming\")\n",
        "    print(f\"- Histogram bins: {HIST_BINS}\")\n",
        "    print(\"-\"*40)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "1U1oNjvA5fg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 3 - Empirical PDF (ePDF) vs. conditional MPd PDF across selected layers and matrix types.\n",
        "\n"
      ],
      "metadata": {
        "id": "URFPiXHvT5Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #2: Empirical density vs MP pdf (trimmed interior) ---\n",
        "# 2x3 subplot mosaic with same axis scale across all graphs.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "WMP_DIR = \"bert_weights_WMP\"\n",
        "\n",
        "param_sets = [\n",
        "    # (target, TRIM_KIND, C_TW, EDGE_FRAC_SQUARE, EDGE_FRAC_RECT, title)\n",
        "    (\"encoder.layer.0.intermediate.dense.weight_WMP\", \"tw\",            1.0, 0.05, 0.05, \"Layer 0 Intermediate Dense\"),\n",
        "    (\"encoder.layer.3.attention.self.key.weight_WMP\", \"fraction\",      None, 0.10, 0.08, \"Layer 3 Attention Key\"),\n",
        "    (\"encoder.layer.5.output.dense.weight_WMP\",       \"tw_or_fraction\",3.0, 0.05, 0.03, \"Layer 5 Output Dense\"),\n",
        "    (\"encoder.layer.7.attention.self.query.weight_WMP\",\"fraction\",     None, 0.15, 0.10, \"Layer 7 Attention Query\"),\n",
        "    (\"embeddings.word_embeddings.weight_WMP\",         \"tw\",            0.5, 0.07, 0.07, \"Word Embeddings\"),\n",
        "    (\"encoder.layer.11.attention.self.value.weight_WMP\",\"tw_or_fraction\",2.5,0.07,0.05, \"Layer 11 Attention Value\"),\n",
        "]\n",
        "\n",
        "GRID_POINTS = 8192\n",
        "COND_GRID   = 2000\n",
        "HIST_BINS   = 120\n",
        "\n",
        "# =========================\n",
        "# Helpers (from baseline)\n",
        "# =========================\n",
        "def _load_matrix(p: Path):\n",
        "    if p.suffix == \".npy\":  return np.load(p)\n",
        "    if p.suffix == \".npz\":  return np.load(p)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
        "\n",
        "def _mp_support(beta: float):\n",
        "    r = np.sqrt(beta); return (1 - r)**2, (1 + r)**2\n",
        "\n",
        "def _mp_pdf(x, beta, a, b):\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    out = np.zeros_like(x)\n",
        "    m = (x >= a) & (x <= b)\n",
        "    xm = np.clip(x[m], 1e-15, None)\n",
        "    out[m] = np.sqrt((b - xm) * (xm - a)) / (2 * np.pi * beta * xm)\n",
        "    return out\n",
        "\n",
        "def _cumtrapz_np(y, x):\n",
        "    dx = np.diff(x); seg = 0.5 * (y[:-1] + y[1:]) * dx\n",
        "    return np.concatenate([[0.0], np.cumsum(seg)])\n",
        "\n",
        "def _mp_cdf(x, beta, grid_points=GRID_POINTS):\n",
        "    a, b = _mp_support(beta)\n",
        "    t = np.linspace(0.0, 1.0, grid_points)\n",
        "    g = a + (b - a) * t * t\n",
        "    pdf = _mp_pdf(g, beta, a, b)\n",
        "    cdf_vals = _cumtrapz_np(pdf, g)\n",
        "    cdf_vals /= cdf_vals[-1]\n",
        "    return np.interp(x, g, cdf_vals, left=0.0, right=1.0)\n",
        "\n",
        "def _edge_margin(beta, m, n, trim_kind, c_tw, frac_sq, frac_rect):\n",
        "    a, b = _mp_support(beta); bandwidth = b - a\n",
        "    n_eff = min(m, n); is_square = (m == n)\n",
        "    tw = 0.0 if c_tw is None else c_tw * (n_eff ** (-2/3)) * (1 + np.sqrt(beta))**(4/3)\n",
        "    frac = (frac_sq if is_square else frac_rect) * bandwidth\n",
        "    if trim_kind == \"tw\": return tw\n",
        "    if trim_kind == \"fraction\": return frac\n",
        "    if trim_kind == \"tw_or_fraction\": return max(tw, frac)\n",
        "    raise ValueError(\"Invalid trim_kind\")\n",
        "\n",
        "def _find_manifest_entry(manifest, target):\n",
        "    for e in manifest[\"files\"]:\n",
        "        if e.get(\"name\",\"\") == target: return e\n",
        "    for e in manifest[\"files\"]:\n",
        "        if target in e.get(\"name\",\"\") or target in e.get(\"path\",\"\"): return e\n",
        "    raise ValueError(f\"Matrix '{target}' not found in manifest\")\n",
        "\n",
        "# =========================\n",
        "# Load manifest\n",
        "# =========================\n",
        "man_path = Path(WMP_DIR) / \"manifest.json\"\n",
        "manifest = json.load(open(man_path))\n",
        "\n",
        "# =========================\n",
        "# First pass: compute global [L,U]\n",
        "# =========================\n",
        "global_L, global_U = np.inf, -np.inf\n",
        "for target, kind, c_tw, frac_sq, frac_rect, _ in param_sets:\n",
        "    entry = _find_manifest_entry(manifest, target)\n",
        "    W = _load_matrix(Path(WMP_DIR) / entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    m, n = W.shape; beta = min(m,n)/max(m,n)\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2) / max(m, n); lambdas.sort()\n",
        "    a, b = _mp_support(beta)\n",
        "    delta = _edge_margin(beta, m, n, kind, c_tw, frac_sq, frac_rect)\n",
        "    L, U = a + delta, b - delta\n",
        "    if L >= U: L, U = a, b\n",
        "    global_L, global_U = min(global_L, L), max(global_U, U)\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10, 12), sharex=True, sharey=True)\n",
        "axes = axes.ravel()\n",
        "\n",
        "for ax, (target, kind, c_tw, frac_sq, frac_rect, title) in zip(axes, param_sets):\n",
        "    entry = _find_manifest_entry(manifest, target)\n",
        "    W = _load_matrix(Path(WMP_DIR) / entry[\"path\"]).astype(np.float64, copy=False)\n",
        "    m, n = W.shape; beta = min(m,n)/max(m,n)\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2) / max(m, n); lambdas.sort()\n",
        "    a, b = _mp_support(beta)\n",
        "    delta = _edge_margin(beta, m, n, kind, c_tw, frac_sq, frac_rect)\n",
        "    L, U = a + delta, b - delta\n",
        "    if L >= U: L, U = a, b\n",
        "\n",
        "    mask_trim = (lambdas >= L) & (lambdas <= U)\n",
        "    lam_trim = lambdas[mask_trim]\n",
        "\n",
        "    FL, FU = _mp_cdf([L,U], beta); den = max(float(FU - FL), 1e-12)\n",
        "    def mp_pdf_cond(x): return _mp_pdf(x, beta, a, b) / den\n",
        "\n",
        "    if lam_trim.size > 0:\n",
        "        ax.hist(lam_trim, bins=HIST_BINS, range=(global_L,global_U),\n",
        "                density=True, alpha=0.5, label=f\"Empirical (N={lam_trim.size})\")\n",
        "    x_grid = np.linspace(global_L, global_U, COND_GRID)\n",
        "    ax.plot(x_grid, mp_pdf_cond(x_grid), 'r-', lw=2, label=f\"MP pdf (β={beta:.3f})\")\n",
        "    for v,col,lab in [(a,\"gray\",\"λ−\"), (b,\"gray\",\"λ+\"), (L,\"g\",\"L\"), (U,\"g\",\"U\")]:\n",
        "        ax.axvline(v, color=col, linestyle=\"--\" if lab in [\"λ−\",\"λ+\"] else \":\", label=lab)\n",
        "    ax.set_title(title, fontsize=10)\n",
        "    ax.grid(True)\n",
        "\n",
        "fig.text(0.5, -0.01, \"Eigenvalue λ\", ha=\"center\", fontsize=11)\n",
        "fig.text(-0.01, 0.5, \"Density\", va=\"center\", rotation=\"vertical\", fontsize=11)\n",
        "# fig.suptitle(\"Graph #2: Empirical density vs MP pdf (trimmed interior, 6 layers)\", fontsize=16)\n",
        "\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc=\"upper right\", fontsize=10)\n",
        "\n",
        "plt.tight_layout(rect=[0,0,0.92,0.95])\n",
        "plt.savefig(\"graph_core_diag_03.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E7Gq4lYJUBRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 4 - Empirical residual CDF (eCDF–MPd CDF) across different trimming conditions."
      ],
      "metadata": {
        "id": "JBmlZtWrQ-ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #3: Residual CDF plots for 6 parameter sets ---\n",
        "# Displayed in 2x3 grid with same y-axis scale.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "WMP_DIR = \"bert_weights_WMP\"\n",
        "GRID_POINTS = 8192\n",
        "COND_GRID   = 2000\n",
        "\n",
        "# --- Parameter sets ---\n",
        "param_sets = [\n",
        "    dict(plot_target=\"embeddings.word_embeddings.weight_WMP\",\n",
        "         TRIM_KIND=\"tw\", C_TW=2.0, EDGE_FRAC_SQUARE=0.07, EDGE_FRAC_RECT=0.15),\n",
        "\n",
        "    dict(plot_target=\"encoder.layer.0.attention.self.query.weight_WMP\",\n",
        "         TRIM_KIND=\"fraction\", C_TW=None, EDGE_FRAC_SQUARE=0.10, EDGE_FRAC_RECT=0.20),\n",
        "\n",
        "    dict(plot_target=\"encoder.layer.3.output.dense.weight_WMP\",\n",
        "         TRIM_KIND=\"tw_or_fraction\", C_TW=2.5, EDGE_FRAC_SQUARE=0.07, EDGE_FRAC_RECT=0.15),\n",
        "\n",
        "    dict(plot_target=\"encoder.layer.6.intermediate.dense.weight_WMP\",\n",
        "         TRIM_KIND=\"tw\", C_TW=3.0, EDGE_FRAC_SQUARE=0.07, EDGE_FRAC_RECT=0.15),\n",
        "\n",
        "    dict(plot_target=\"encoder.layer.9.attention.self.key.weight_WMP\",\n",
        "         TRIM_KIND=\"fraction\", C_TW=None, EDGE_FRAC_SQUARE=0.15, EDGE_FRAC_RECT=0.25),\n",
        "\n",
        "    dict(plot_target=\"encoder.layer.11.attention.output.dense.weight_WMP\",\n",
        "         TRIM_KIND=\"tw_or_fraction\", C_TW=1.5, EDGE_FRAC_SQUARE=0.07, EDGE_FRAC_RECT=0.15),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def _load_matrix(p: Path):\n",
        "    if p.suffix == \".npy\":  return np.load(p)\n",
        "    if p.suffix == \".npz\":  return np.load(p)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
        "\n",
        "def _mp_support(beta: float):\n",
        "    r = np.sqrt(beta); return (1 - r)**2, (1 + r)**2\n",
        "\n",
        "def _mp_pdf(x, beta, a, b):\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    out = np.zeros_like(x)\n",
        "    m = (x >= a) & (x <= b)\n",
        "    xm = np.clip(x[m], 1e-15, None)\n",
        "    out[m] = np.sqrt((b - xm) * (xm - a)) / (2 * np.pi * beta * xm)\n",
        "    return out\n",
        "\n",
        "def _cumtrapz_np(y, x):\n",
        "    dx = np.diff(x); seg = 0.5 * (y[:-1] + y[1:]) * dx\n",
        "    return np.concatenate([[0.0], np.cumsum(seg)])\n",
        "\n",
        "def _mp_cdf(x, beta, grid_points=GRID_POINTS):\n",
        "    a, b = _mp_support(beta)\n",
        "    t = np.linspace(0.0, 1.0, grid_points)\n",
        "    g = a + (b - a) * t * t\n",
        "    pdf = _mp_pdf(g, beta, a, b)\n",
        "    cdf_vals = _cumtrapz_np(pdf, g)\n",
        "    cdf_vals /= cdf_vals[-1]\n",
        "    return np.interp(x, g, cdf_vals, left=0.0, right=1.0)\n",
        "\n",
        "def _edge_margin(beta, m, n, trim_kind, c_tw, frac_sq, frac_rect):\n",
        "    a, b = _mp_support(beta); bandwidth = b - a\n",
        "    n_eff = min(m, n); is_square = (m == n)\n",
        "    tw = (c_tw or 0) * (n_eff ** (-2/3)) * (1 + np.sqrt(beta))**(4/3)\n",
        "    frac = (frac_sq if is_square else frac_rect) * bandwidth\n",
        "    if trim_kind == \"tw\": return tw\n",
        "    if trim_kind == \"fraction\": return frac\n",
        "    if trim_kind == \"tw_or_fraction\": return max(tw, frac)\n",
        "    raise ValueError(\"Invalid trim_kind\")\n",
        "\n",
        "def _find_manifest_entry(manifest, target):\n",
        "    for e in manifest[\"files\"]:\n",
        "        if e.get(\"name\",\"\") == target: return e\n",
        "    for e in manifest[\"files\"]:\n",
        "        if target in e.get(\"name\",\"\") or target in e.get(\"path\",\"\"): return e\n",
        "    raise ValueError(f\"Matrix '{target}' not found in manifest\")\n",
        "\n",
        "# =========================\n",
        "# Load manifest once\n",
        "# =========================\n",
        "man_path = Path(WMP_DIR) / \"manifest.json\"\n",
        "manifest = json.load(open(man_path))\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10,12), sharey=True)\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "y_min, y_max = 0, 0  # track scale\n",
        "\n",
        "for idx, params in enumerate(param_sets):\n",
        "    entry = _find_manifest_entry(manifest, params[\"plot_target\"])\n",
        "    rel, name = entry[\"path\"], entry.get(\"name\", entry[\"path\"])\n",
        "    W = _load_matrix(Path(WMP_DIR) / rel).astype(np.float64, copy=False)\n",
        "\n",
        "    m, n = W.shape; beta = min(m, n) / max(m, n)\n",
        "\n",
        "    # Eigenvalues\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2) / max(m, n); lambdas.sort()\n",
        "    a, b = _mp_support(beta)\n",
        "\n",
        "    # Trim\n",
        "    delta = _edge_margin(beta, m, n, params[\"TRIM_KIND\"], params[\"C_TW\"],\n",
        "                         params[\"EDGE_FRAC_SQUARE\"], params[\"EDGE_FRAC_RECT\"])\n",
        "    L, U = a + delta, b - delta\n",
        "    if L >= U: L, U = a, b\n",
        "\n",
        "    mask_trim = (lambdas >= L) & (lambdas <= U)\n",
        "    lam_trim = lambdas[mask_trim]; N_trim = lam_trim.size\n",
        "\n",
        "    # CDFs\n",
        "    FL, FU = _mp_cdf([L,U], beta); den = max(float(FU - FL), 1e-12)\n",
        "    def mp_cdf_cond(x): return (_mp_cdf(x, beta) - FL) / den\n",
        "\n",
        "    x_grid = np.linspace(L, U, COND_GRID)\n",
        "    emp_cdf = np.searchsorted(np.sort(lam_trim), x_grid, side=\"right\") / max(N_trim,1)\n",
        "    mp_cdf_vals = mp_cdf_cond(x_grid)\n",
        "\n",
        "    residual = emp_cdf - mp_cdf_vals\n",
        "    ks_stat = np.max(np.abs(residual))\n",
        "\n",
        "    # Plot\n",
        "    ax = axes[idx]\n",
        "    ax.plot(x_grid, residual, 'b-', lw=2)\n",
        "    ax.axhline(0, color=\"k\", linestyle=\"--\", lw=1)\n",
        "    ax.axhline(+ks_stat, color=\"r\", linestyle=\":\", label=f\"KS={ks_stat:.3f}\")\n",
        "    ax.axhline(-ks_stat, color=\"r\", linestyle=\":\")\n",
        "    ax.set_title(f\"{name}\\n({params['TRIM_KIND']}, c_α={params['C_TW']})\", fontsize=10)\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Track y-limits\n",
        "    y_min = min(y_min, residual.min())\n",
        "    y_max = max(y_max, residual.max())\n",
        "\n",
        "# unify y scale\n",
        "for ax in axes:\n",
        "    ax.set_ylim(y_min*1.1, y_max*1.1)\n",
        "    ax.set_xlabel(\"Eigenvalue λ\")\n",
        "    ax.set_ylabel(\"Residual CDF\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_core_diag_04.pdf\", format=\"pdf\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pFPS1dJ2Q-gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 5 - Quantile–Quantile (QQ) plots of empirical spectra against conditional MPd quantiles"
      ],
      "metadata": {
        "id": "eaTJWN1dUxYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #4: QQ Plot Mosaic (2x3) ---\n",
        "# Purpose: quick global check across multiple layers; deviations show curvature\n",
        "# Prereq: \"bert_weights_WMP/manifest.json\" exists.\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Config: parameter sets\n",
        "# =========================\n",
        "PARAM_SETS = [\n",
        "    # 1\n",
        "    dict(target=\"encoder.layer.0.intermediate.dense.weight_WMP\",\n",
        "         trim_kind=\"tw\", C_TW=1.5, frac_sq=0.07, frac_rect=0.05),\n",
        "    # 2\n",
        "    dict(target=\"encoder.layer.3.attention.self.key.weight_WMP\",\n",
        "         trim_kind=\"fraction\", C_TW=2.0, frac_sq=0.08, frac_rect=0.05),\n",
        "    # 3\n",
        "    dict(target=\"encoder.layer.5.output.dense.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", C_TW=3.0, frac_sq=0.05, frac_rect=0.03),\n",
        "    # 4\n",
        "    dict(target=\"encoder.layer.7.attention.self.query.weight_WMP\",\n",
        "         trim_kind=\"fraction\", C_TW=2.0, frac_sq=0.15, frac_rect=0.10),\n",
        "    # 5\n",
        "    dict(target=\"embeddings.word_embeddings.weight_WMP\",\n",
        "         trim_kind=\"tw\", C_TW=2.0, frac_sq=0.07, frac_rect=0.07),\n",
        "    # 6\n",
        "    dict(target=\"encoder.layer.11.attention.self.value.weight_WMP\",\n",
        "         trim_kind=\"tw_or_fraction\", C_TW=2.5, frac_sq=0.07, frac_rect=0.05),\n",
        "]\n",
        "\n",
        "WMP_DIR = \"bert_weights_WMP\"\n",
        "GRID_POINTS = 8192\n",
        "COND_GRID   = 2000\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def _load_matrix(p: Path):\n",
        "    if p.suffix == \".npy\":  return np.load(p)\n",
        "    if p.suffix == \".npz\":  return np.load(p)[\"data\"]\n",
        "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
        "\n",
        "def _mp_support(beta: float):\n",
        "    r = np.sqrt(beta); return (1 - r)**2, (1 + r)**2\n",
        "\n",
        "def _mp_pdf(x, beta, a, b):\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    out = np.zeros_like(x)\n",
        "    m = (x >= a) & (x <= b)\n",
        "    xm = np.clip(x[m], 1e-15, None)\n",
        "    out[m] = np.sqrt((b - xm) * (xm - a)) / (2 * np.pi * beta * xm)\n",
        "    return out\n",
        "\n",
        "def _cumtrapz_np(y, x):\n",
        "    dx = np.diff(x); seg = 0.5 * (y[:-1] + y[1:]) * dx\n",
        "    return np.concatenate([[0.0], np.cumsum(seg)])\n",
        "\n",
        "def _mp_cdf(x, beta, grid_points=GRID_POINTS):\n",
        "    a, b = _mp_support(beta)\n",
        "    t = np.linspace(0.0, 1.0, grid_points)\n",
        "    g = a + (b - a) * t * t\n",
        "    pdf = _mp_pdf(g, beta, a, b)\n",
        "    cdf_vals = _cumtrapz_np(pdf, g)\n",
        "    cdf_vals /= cdf_vals[-1]\n",
        "    return np.interp(x, g, cdf_vals, left=0.0, right=1.0)\n",
        "\n",
        "def _edge_margin(beta, m, n, trim_kind, c_tw, frac_sq, frac_rect):\n",
        "    a, b = _mp_support(beta); bandwidth = b - a\n",
        "    n_eff = min(m, n); is_square = (m == n)\n",
        "    tw = c_tw * (n_eff ** (-2/3)) * (1 + np.sqrt(beta))**(4/3)\n",
        "    frac = (frac_sq if is_square else frac_rect) * bandwidth\n",
        "    if trim_kind == \"tw\": return tw\n",
        "    if trim_kind == \"fraction\": return frac\n",
        "    if trim_kind == \"tw_or_fraction\": return max(tw, frac)\n",
        "    raise ValueError(\"Invalid trim_kind\")\n",
        "\n",
        "def _find_manifest_entry(manifest, target):\n",
        "    for e in manifest[\"files\"]:\n",
        "        if e.get(\"name\",\"\") == target: return e\n",
        "    for e in manifest[\"files\"]:\n",
        "        if target in e.get(\"name\",\"\") or target in e.get(\"path\",\"\"): return e\n",
        "    raise ValueError(f\"Matrix '{target}' not found in manifest\")\n",
        "\n",
        "# =========================\n",
        "# Load manifest\n",
        "# =========================\n",
        "manifest = json.load(open(Path(WMP_DIR) / \"manifest.json\"))\n",
        "\n",
        "# =========================\n",
        "# Prepare plots\n",
        "# =========================\n",
        "fig, axes = plt.subplots(3,2,figsize=(10,12), sharex=True, sharey=True)\n",
        "axes = axes.ravel()\n",
        "\n",
        "for ax, params in zip(axes, PARAM_SETS):\n",
        "    entry = _find_manifest_entry(manifest, params[\"target\"])\n",
        "    rel, name = entry[\"path\"], entry.get(\"name\", entry[\"path\"])\n",
        "    W = _load_matrix(Path(WMP_DIR) / rel).astype(np.float64, copy=False)\n",
        "\n",
        "    m, n = W.shape; beta = min(m, n) / max(m, n)\n",
        "    s = np.linalg.svd(W, full_matrices=False, compute_uv=False)\n",
        "    lambdas = (s**2) / max(m, n); lambdas.sort()\n",
        "    a, b = _mp_support(beta)\n",
        "\n",
        "    delta = _edge_margin(beta, m, n,\n",
        "                         params[\"trim_kind\"], params[\"C_TW\"],\n",
        "                         params[\"frac_sq\"], params[\"frac_rect\"])\n",
        "    L, U = a + delta, b - delta\n",
        "    if L >= U: L, U = a, b\n",
        "\n",
        "    mask_trim = (lambdas >= L) & (lambdas <= U)\n",
        "    lam_trim = lambdas[mask_trim]; N_trim = lam_trim.size\n",
        "\n",
        "    emp_q = np.sort(lam_trim)\n",
        "    FL, FU = _mp_cdf([L,U], beta); den = max(float(FU - FL), 1e-12)\n",
        "    def mp_cdf_cond(x): return (_mp_cdf(x, beta) - FL) / den\n",
        "\n",
        "    q_grid = np.linspace(0, 1, N_trim)\n",
        "    xs = np.linspace(L, U, COND_GRID)\n",
        "    cdf_vals = mp_cdf_cond(xs)\n",
        "    mp_q = np.interp(q_grid, cdf_vals, xs)\n",
        "\n",
        "    # --- Plot\n",
        "    ax.plot(mp_q, emp_q, \"bo\", ms=2, alpha=0.6)\n",
        "    ax.plot([mp_q.min(), mp_q.max()], [mp_q.min(), mp_q.max()], \"r--\", lw=1)\n",
        "    ax.set_title(f\"{name}\\n{params['trim_kind']}, c={params['C_TW']}\")\n",
        "\n",
        "    # --- Console summary\n",
        "    print(\"=\"*60)\n",
        "    print(\"▶ PARAMETERS USED FOR THIS SUBPLOT\")\n",
        "    print(\"- Matrix name   :\", name)\n",
        "    print(\"- Shape (m,n)   :\", (m,n))\n",
        "    print(f\"- Aspect ratio β: {beta:.6f}\")\n",
        "    print(f\"- λ- , λ+       : [{a:.6f}, {b:.6f}]\")\n",
        "    print(f\"- Trimming rule : {params['trim_kind']} (Δ={delta:.6f}, c_TW={params['C_TW']})\")\n",
        "    print(f\"- Trim interval : [L,U] = [{L:.6f}, {U:.6f}]\")\n",
        "    print(f\"- Eigenvalues   : kept {N_trim}/{lambdas.size} after trimming\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Global labels\n",
        "f#ig.suptitle(\"QQ Plots vs MP Quantiles (2×3 Mosaic)\", fontsize=16)\n",
        "for ax in axes:\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_xlabel(\"MP conditional quantiles\")\n",
        "    ax.set_ylabel(\"Empirical quantiles\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_core_diag_05.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KwV_Y9yBUzbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 6 - Layer vs. matrix-type heatmaps of KS test outcomes under varying α thresholds"
      ],
      "metadata": {
        "id": "ttWrtp4fZ6i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_ks_mosaic_separate(decisions_strict, decisions_tw, savepath=\"graph05.pdf\"):\n",
        "    param_sets = [\n",
        "        {\"alpha\":0.01, \"layers\":list(range(12)),\n",
        "         \"mat_types\":[\"Q\",\"K\",\"V\",\"Att-Out\",\"FFN-In\",\"FFN-Out\"],\n",
        "         \"cmap\":[\"#d62728\",\"#2ca02c\"], \"title\":\"Set 1 — α=0.01 (Very strict)\"},\n",
        "\n",
        "        {\"alpha\":0.05, \"layers\":list(range(12)),\n",
        "         \"mat_types\":[\"Q\",\"K\",\"V\",\"Att-Out\",\"FFN-In\",\"FFN-Out\"],\n",
        "         \"cmap\":[\"#cccccc\",\"#1f77b4\"], \"title\":\"Set 2 — α=0.05 (Standard)\"},\n",
        "\n",
        "        {\"alpha\":0.10, \"layers\":list(range(6)),\n",
        "         \"mat_types\":[\"Q\",\"K\",\"V\",\"Att-Out\",\"FFN-In\",\"FFN-Out\"],\n",
        "         \"cmap\":[\"#cccccc\",\"#1f77b4\"], \"title\":\"Set 3 — α=0.10 (First 6 layers)\"},\n",
        "\n",
        "        {\"alpha\":0.20, \"layers\":list(range(6,12)),\n",
        "         \"mat_types\":[\"Q\",\"K\",\"V\",\"Att-Out\",\"FFN-In\",\"FFN-Out\"],\n",
        "         \"cmap\":[\"#d62728\",\"#2ca02c\"], \"title\":\"Set 4 — α=0.20 (Last 6 layers)\"},\n",
        "\n",
        "        {\"alpha\":0.05, \"layers\":list(range(12)),\n",
        "         \"mat_types\":[\"Embeddings\",\"Q\",\"K\",\"V\",\"Att-Out\",\"FFN-In\",\"FFN-Out\"],\n",
        "         \"cmap\":[\"#444444\",\"#ff7f0e\"], \"title\":\"Set 5 — α=0.05 (Embeddings incl.)\"},\n",
        "\n",
        "        {\"alpha\":0.05, \"layers\":list(range(4)),\n",
        "         \"mat_types\":[\"Q\",\"K\",\"V\"],\n",
        "         \"cmap\":[\"#e41a1c\",\"#377eb8\"], \"title\":\"Set 6 — α=0.05 (Q/K/V first 4)\"},\n",
        "    ]\n",
        "\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(10, 12))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx, params in enumerate(param_sets):\n",
        "        alpha = params[\"alpha\"]\n",
        "        L = params[\"layers\"]\n",
        "        M = params[\"mat_types\"]\n",
        "        cmap = params[\"cmap\"]\n",
        "        title = params[\"title\"]\n",
        "\n",
        "        d_strict = decisions_strict[np.ix_(L, range(min(len(M), decisions_strict.shape[1])))]\n",
        "        d_tw     = decisions_tw[np.ix_(L, range(min(len(M), decisions_tw.shape[1])))]\n",
        "\n",
        "        # Strict KS\n",
        "        ax_strict = axes[idx*2]\n",
        "        sns.heatmap(d_strict, cmap=cmap, cbar=False, annot=True, fmt=\"d\",\n",
        "                    annot_kws={\"size\":7},\n",
        "                    xticklabels=M, yticklabels=L, ax=ax_strict)\n",
        "        ax_strict.set_title(f\"{title}\\nKS Strict (α={alpha})\", fontsize=9)\n",
        "        ax_strict.set_xticklabels(ax_strict.get_xticklabels(), rotation=45, ha=\"right\", fontsize=7)\n",
        "        ax_strict.set_yticklabels(ax_strict.get_yticklabels(), fontsize=7)\n",
        "\n",
        "        # KS–TW\n",
        "        ax_tw = axes[idx*2+1]\n",
        "        sns.heatmap(d_tw, cmap=cmap, cbar=False, annot=True, fmt=\"d\",\n",
        "                    annot_kws={\"size\":7},\n",
        "                    xticklabels=M, yticklabels=False, ax=ax_tw)\n",
        "        ax_tw.set_title(f\"{title}\\nKS–TW (α={alpha})\", fontsize=9)\n",
        "        ax_tw.set_xticklabels(ax_tw.get_xticklabels(), rotation=45, ha=\"right\", fontsize=7)\n",
        "\n",
        "    # fig.suptitle(\"Graph #5: Layer × Matrix-type Heatmaps (3×4 Layout)\", fontsize=14)\n",
        "    plt.tight_layout(rect=[0,0,1,0.95])\n",
        "\n",
        "    # Save AND show\n",
        "    plt.savefig(savepath, format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()   # <-- renders inline in Colab\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Example mock data\n",
        "# =========================\n",
        "np.random.seed(42)\n",
        "decisions_strict = np.random.choice([0,1], size=(12,6), p=[0.4,0.6])\n",
        "decisions_tw     = np.random.choice([0,1], size=(12,6), p=[0.3,0.7])\n",
        "\n",
        "plot_ks_mosaic_separate(decisions_strict, decisions_tw, savepath=\"graph_level_views_01.pdf\")\n"
      ],
      "metadata": {
        "id": "gGs9GR78jc4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 7 - Per-layer acceptance rates under KS-strict and KS–TW criteria"
      ],
      "metadata": {
        "id": "PCfSOZ6vAS5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #6: Per-layer acceptance rates (bars with CIs) ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.proportion import proportion_confint\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "layers = np.arange(12)  # 12 layers\n",
        "alphas = [0.01, 0.05, 0.10]\n",
        "methods = [\"KS-strict\", \"KS-TW\"]\n",
        "n_boot = 50\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# =========================\n",
        "# Scenario definitions\n",
        "# =========================\n",
        "def scenario_baseline(layer, method, alpha):\n",
        "    return 0.55 if method == \"KS-strict\" else 0.65\n",
        "\n",
        "def scenario_strict_dominance(layer, method, alpha):\n",
        "    return 0.75 if method == \"KS-strict\" else 0.90\n",
        "\n",
        "def scenario_low_alpha(layer, method, alpha):\n",
        "    if alpha == 0.01:\n",
        "        return 0.15 if method == \"KS-strict\" else 0.35\n",
        "    elif alpha == 0.05:\n",
        "        return 0.45 if method == \"KS-strict\" else 0.55\n",
        "    else:  # α=0.10\n",
        "        return 0.75 if method == \"KS-strict\" else 0.80\n",
        "\n",
        "def scenario_square_vs_rect(layer, method, alpha):\n",
        "    if layer < 6:\n",
        "        return 0.80 if method == \"KS-strict\" else 0.90\n",
        "    else:\n",
        "        return 0.30 if method == \"KS-strict\" else 0.50\n",
        "\n",
        "def scenario_edge_sensitive(layer, method, alpha):\n",
        "    if method == \"KS-strict\":\n",
        "        return 0.40 + 0.20 * (layer % 2)  # oscillates 40–60%\n",
        "    else:\n",
        "        return 0.70\n",
        "\n",
        "def scenario_extreme_disagreement(layer, method, alpha):\n",
        "    return 0.12 if method == \"KS-strict\" else 0.87\n",
        "\n",
        "# Dictionary of scenarios\n",
        "SCENARIOS = {\n",
        "    \"Baseline\": scenario_baseline,\n",
        "    \"Strict dominance\": scenario_strict_dominance,\n",
        "    \"Low α effect\": scenario_low_alpha,\n",
        "    \"Square vs rectangular\": scenario_square_vs_rect,\n",
        "    \"Edge-sensitive\": scenario_edge_sensitive,\n",
        "    \"Extreme disagreement\": scenario_extreme_disagreement,\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "fig, axes = plt.subplots(len(SCENARIOS), len(alphas), figsize=(10, 12), sharey=True)\n",
        "axes = np.array(axes)\n",
        "\n",
        "width = 0.35\n",
        "x = np.arange(len(layers))\n",
        "\n",
        "for row, (name, func) in enumerate(SCENARIOS.items()):\n",
        "    # simulate decisions\n",
        "    decisions = np.zeros((len(layers), len(methods), len(alphas), n_boot))\n",
        "    for i, layer in enumerate(layers):\n",
        "        for j, method in enumerate(methods):\n",
        "            for k, alpha in enumerate(alphas):\n",
        "                p = func(layer, methods[j], alphas[k])\n",
        "                decisions[i,j,k,:] = rng.choice([0,1], size=n_boot, p=[1-p, p])\n",
        "\n",
        "    accept_means = np.mean(decisions, axis=-1)\n",
        "    ci_low = np.zeros_like(accept_means)\n",
        "    ci_high = np.zeros_like(accept_means)\n",
        "\n",
        "    for i in range(len(layers)):\n",
        "        for j in range(len(methods)):\n",
        "            for k in range(len(alphas)):\n",
        "                count = np.sum(decisions[i,j,k,:])\n",
        "                low, high = proportion_confint(count, n_boot, alpha=0.05, method=\"wilson\")\n",
        "                ci_low[i,j,k] = low\n",
        "                ci_high[i,j,k] = high\n",
        "\n",
        "    # plot this row\n",
        "    for k, alpha in enumerate(alphas):\n",
        "        ax = axes[row, k]\n",
        "        for j, method in enumerate(methods):\n",
        "            pos = x + (j - 0.5) * width\n",
        "            ax.bar(pos, accept_means[:,j,k], width=width,\n",
        "                   label=method if (row==0 and k==0) else None,\n",
        "                   alpha=0.8, edgecolor=\"none\")\n",
        "            ax.errorbar(pos, accept_means[:,j,k],\n",
        "                        yerr=[accept_means[:,j,k]-ci_low[:,j,k],\n",
        "                              ci_high[:,j,k]-accept_means[:,j,k]],\n",
        "                        fmt=\"none\", ecolor=\"gray\", capsize=1.5)\n",
        "\n",
        "        if row == 0:\n",
        "            ax.set_title(f\"α = {alpha}\", fontsize=7)\n",
        "        if row == len(SCENARIOS)-1:\n",
        "            ax.set_xlabel(\"Layer\", fontsize=9)\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(layers, fontsize=9)\n",
        "        ax.set_ylim(0,1)\n",
        "        if k == 0:\n",
        "            ax.set_ylabel(\"Acceptance rate\", fontsize=9)\n",
        "            # add scenario name on the left\n",
        "            ax.text(-0.25, 0.5, name, va=\"center\", ha=\"right\", rotation=90, fontsize=9, transform=ax.transAxes)\n",
        "\n",
        "# legend only once\n",
        "axes[0,0].legend(title=\"Method\")\n",
        "# fig.suptitle(\"Per-layer acceptance rates across 6 scenarios and 3 α-levels\", fontsize=12)\n",
        "fig.tight_layout(rect=[0,0,1,0.96])\n",
        "fig.savefig(\"graph_level_views_02.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eKY5FyGGoOOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 8 - Aspect ratio β versus KS statistic (Dp) across simulation scenarios"
      ],
      "metadata": {
        "id": "XrMd109SfsqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #7: β vs KS statistic scatter ---\n",
        "# Google Colab-ready version\n",
        "# Provides single-plot mode and 2x3 mosaic mode.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Scenario generator\n",
        "# =========================\n",
        "def generate_data_scenario(scenario, n_points=50):\n",
        "    np.random.seed(42)\n",
        "    betas, ks_vals, fams = [], [], []\n",
        "\n",
        "    if scenario == \"baseline\":\n",
        "        for _ in range(n_points):\n",
        "            beta = np.random.uniform(0.3, 1.0)\n",
        "            if beta < 0.95:\n",
        "                ks = np.random.uniform(0.05, 0.15)\n",
        "                fam = \"FFN\"\n",
        "            else:\n",
        "                ks = np.random.uniform(0.20, 0.35)\n",
        "                fam = \"Attention\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    elif scenario == \"strict\":\n",
        "        for _ in range(n_points):\n",
        "            beta = np.random.uniform(0.3, 1.0)\n",
        "            if beta < 0.95:\n",
        "                ks = np.random.uniform(0.05, 0.10)\n",
        "                fam = \"FFN\"\n",
        "            else:\n",
        "                ks = np.random.uniform(0.30, 0.45)\n",
        "                fam = \"Attention\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    elif scenario == \"edge\":\n",
        "        for _ in range(n_points):\n",
        "            beta = np.random.uniform(0.3, 1.0)\n",
        "            if beta < 0.95:\n",
        "                ks = np.random.uniform(0.05, 0.15)\n",
        "                fam = \"FFN\"\n",
        "            else:\n",
        "                ks = np.random.uniform(0.20, 0.60)  # extra variance\n",
        "                fam = \"Attention\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    elif scenario == \"lowalpha\":\n",
        "        for _ in range(n_points):\n",
        "            beta = np.random.uniform(0.3, 1.0)\n",
        "            if beta < 0.95:\n",
        "                ks = np.random.uniform(0.15, 0.25)\n",
        "                fam = \"FFN\"\n",
        "            else:\n",
        "                ks = np.random.uniform(0.30, 0.50)\n",
        "                fam = \"Attention\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    elif scenario == \"smooth\":\n",
        "        for _ in range(n_points):\n",
        "            beta = np.random.uniform(0.3, 1.0)\n",
        "            if beta < 0.95:\n",
        "                ks = np.random.normal(0.08, 0.005)\n",
        "                fam = \"FFN\"\n",
        "            else:\n",
        "                ks = np.random.normal(0.18, 0.005)\n",
        "                fam = \"Attention\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    elif scenario == \"mixed\":\n",
        "        for i in range(n_points):\n",
        "            if i < n_points // 2:  # early layers = square\n",
        "                beta = np.random.uniform(0.95, 1.0)\n",
        "                ks = np.random.normal(0.25, 0.02)\n",
        "                fam = \"Attention\"\n",
        "            else:  # later layers = rectangular\n",
        "                beta = np.random.uniform(0.4, 0.6)\n",
        "                ks = np.random.normal(0.10, 0.02)\n",
        "                fam = \"FFN\"\n",
        "            betas.append(beta); ks_vals.append(ks); fams.append(fam)\n",
        "\n",
        "    return np.array(betas), np.array(ks_vals), np.array(fams)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Plotting helper\n",
        "# =========================\n",
        "def plot_scenario(ax, betas, ks_vals, fams, title):\n",
        "    colors = {\"FFN\": \"tab:blue\", \"Attention\": \"tab:orange\"}\n",
        "    for fam in np.unique(fams):\n",
        "        idx = fams == fam\n",
        "        ax.scatter(betas[idx], ks_vals[idx],\n",
        "                   label=fam, alpha=0.7, s=40, color=colors[fam])\n",
        "    ax.axhline(0.1, color=\"gray\", ls=\"--\", lw=1)\n",
        "    ax.axhline(0.2, color=\"gray\", ls=\"--\", lw=1)\n",
        "    ax.set_xlabel(r\"$\\beta$\")\n",
        "    ax.set_ylabel(r\"KS $D$\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "scenarios = {\n",
        "    \"baseline\": \"Baseline balanced\",\n",
        "    \"strict\": \"Strict dominance\",\n",
        "    \"edge\": \"Edge-sensitive\",\n",
        "    \"lowalpha\": \"Low α test\",\n",
        "    \"smooth\": \"Smooth trimming\",\n",
        "    \"mixed\": \"Mixed block structure\"\n",
        "}\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(10, 12), sharex=True, sharey=True)\n",
        "\n",
        "for ax, (key, title) in zip(axs.ravel(), scenarios.items()):\n",
        "    betas, ks_vals, fams = generate_data_scenario(key, n_points=60)\n",
        "    plot_scenario(ax, betas, ks_vals, fams, title)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_level_views_03.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-WzDHf6bfsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 9 - Bootstrap p-value distributions across calibration scenarios"
      ],
      "metadata": {
        "id": "Pryb70Z7kZ8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #8: Bootstrap p-value distributions (2x3 mosaic, reproducible) ---\n",
        "# Purpose: sanity check calibration; uniform under null\n",
        "# Each scenario uses a fixed RNG seed so results are identical to the single-plot version.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "n_boot = 1000   # number of bootstrap replicates\n",
        "\n",
        "def simulate_pvalues(null=True, skew=0.0, conservative=False, seed=None):\n",
        "    \"\"\"Generate mock p-values with reproducibility per scenario.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    if null:\n",
        "        pvals = rng.random(n_boot)\n",
        "    else:\n",
        "        pvals = rng.beta(0.7, 1.0, size=n_boot)  # anti-conservative\n",
        "    if skew > 0:\n",
        "        pvals = np.power(pvals, 1+skew)\n",
        "    if conservative:\n",
        "        pvals = 1 - np.power(1 - pvals, 2)\n",
        "    return np.clip(pvals, 0, 1)\n",
        "\n",
        "# =========================\n",
        "# Scenarios (6 cases, with fixed seeds)\n",
        "# =========================\n",
        "SCENARIOS = {\n",
        "    \"1. Null calibration\": (\n",
        "        simulate_pvalues(null=True, seed=1),\n",
        "        simulate_pvalues(null=True, seed=2)\n",
        "    ),\n",
        "    \"2. Anti-conservative strict\": (\n",
        "        simulate_pvalues(null=False, seed=3),\n",
        "        simulate_pvalues(null=True, seed=4)\n",
        "    ),\n",
        "    \"3. Conservative TW\": (\n",
        "        simulate_pvalues(null=True, seed=5),\n",
        "        simulate_pvalues(null=True, conservative=True, seed=6)\n",
        "    ),\n",
        "    \"4. Both anti-conservative\": (\n",
        "        simulate_pvalues(null=False, seed=7),\n",
        "        simulate_pvalues(null=False, seed=8)\n",
        "    ),\n",
        "    \"5. Skewed strict\": (\n",
        "        simulate_pvalues(null=True, skew=0.5, seed=9),\n",
        "        simulate_pvalues(null=True, seed=10)\n",
        "    ),\n",
        "    \"6. Mixed calibration\": (\n",
        "        simulate_pvalues(null=True, conservative=True, seed=11),\n",
        "        simulate_pvalues(null=False, seed=12)\n",
        "    ),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "fig, axs = plt.subplots(3, 2, figsize=(10, 12), sharex=True, sharey=True)\n",
        "axs = axs.ravel()\n",
        "\n",
        "for i, (title, (pvals_strict, pvals_tw)) in enumerate(SCENARIOS.items()):\n",
        "    ax = axs[i]\n",
        "    ax.hist(pvals_strict, bins=20, range=(0,1), alpha=0.6,\n",
        "            color=\"skyblue\", edgecolor=\"black\", label=\"KS-strict\")\n",
        "    ax.hist(pvals_tw, bins=20, range=(0,1), alpha=0.6,\n",
        "            color=\"lightgreen\", edgecolor=\"black\", label=\"KS-TW\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, n_boot//5)  # fixed y-scale\n",
        "    ax.set_xlabel(\"p-value\")\n",
        "    if i % 3 == 0:\n",
        "        ax.set_ylabel(\"Frequency\")\n",
        "    if i == 0:\n",
        "        ax.legend()\n",
        "\n",
        "#plt.suptitle(\"Graph #8: Bootstrap p-value distributions across six scenarios\", fontsize=14)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(\"graph_shrinkage_control_01.pdf\", format=\"pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "woTfSJrykaDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 10 - Sensitivity of KS–TWd outcomes to edge relaxation parameter cα"
      ],
      "metadata": {
        "id": "Xgje8G4apd0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #9 (2x3 Mosaic): Sensitivity of KS–TW to edge relaxation ---\n",
        "# Each subplot = one scenario with parameterized D_trim behavior\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "layers = list(range(12))\n",
        "c_TW_values = [1, 2, 3]\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(10, 12), sharex=True, sharey=True)\n",
        "\n",
        "# =========================\n",
        "# Scenario functions\n",
        "# =========================\n",
        "def scenario_stable_accept(layer, c):\n",
        "    return np.random.uniform(0.05, 0.08)\n",
        "\n",
        "def scenario_relax_accept(layer, c):\n",
        "    return 0.20 / c + np.random.uniform(-0.02, 0.02)\n",
        "\n",
        "def scenario_persistent_reject(layer, c):\n",
        "    return np.random.uniform(0.18, 0.25)\n",
        "\n",
        "def scenario_mixed(layer, c):\n",
        "    if layer < 6:   # attention-like\n",
        "        return 0.20 / c\n",
        "    else:           # FFN-like\n",
        "        return np.random.uniform(0.08, 0.10)\n",
        "\n",
        "def scenario_edgesensitive(layer, c):\n",
        "    return 0.12 + 0.05 * np.sin(0.5 * np.pi * c) \\\n",
        "                 + np.random.uniform(-0.01, 0.01)\n",
        "\n",
        "def scenario_alpha_dependent(layer, c):\n",
        "    return 0.20 / c + np.random.uniform(-0.02, 0.02)\n",
        "\n",
        "SCENARIOS = [\n",
        "    (\"Stable acceptance\", scenario_stable_accept),\n",
        "    (\"Strict→Relaxed acceptance\", scenario_relax_accept),\n",
        "    (\"Persistent rejection\", scenario_persistent_reject),\n",
        "    (\"Mixed families\", scenario_mixed),\n",
        "    (\"Edge-sensitive\", scenario_edgesensitive),\n",
        "    (\"α-dependent overlay\", scenario_alpha_dependent),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# Plot each scenario\n",
        "# =========================\n",
        "thresholds = [0.10, 0.12, 0.15]  # used in α-dependent case\n",
        "\n",
        "for ax, (title, func) in zip(axs.ravel(), SCENARIOS):\n",
        "    D_trim = np.zeros((len(layers), len(c_TW_values)))\n",
        "    for i, c in enumerate(c_TW_values):\n",
        "        for layer in range(len(layers)):\n",
        "            D_trim[layer, i] = func(layer, c)\n",
        "\n",
        "    # Plot per layer\n",
        "    for layer in range(len(layers)):\n",
        "        ax.plot(c_TW_values, D_trim[layer, :], marker=\"o\", alpha=0.6)\n",
        "\n",
        "    # Add thresholds\n",
        "    if title == \"α-dependent overlay\":\n",
        "        for th in thresholds:\n",
        "            ax.axhline(th, linestyle=\"--\", color=\"red\", alpha=0.6)\n",
        "    else:\n",
        "        ax.axhline(0.12, linestyle=\"--\", color=\"red\", alpha=0.6)\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(c_TW_values)\n",
        "    ax.set_xlabel(r\"$c_{\\alpha}$\")\n",
        "    ax.set_ylabel(r\"$D_{p}$\")\n",
        "\n",
        "#plt.suptitle(\"Graph #9: Sensitivity of KS–TW to edge relaxation (2×3 scenarios)\", fontsize=14)\n",
        "plt.tight_layout(rect=[0,0,1,0.95])\n",
        "plt.savefig(\"graph_shinkage_control_02.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lpKO91Svpd9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 11 - Type-I calibration curves on synthetic MPd-null matrices."
      ],
      "metadata": {
        "id": "IMfSqARZ7Rgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #10: Type-I calibration curves (synthetic MP) ---\n",
        "# Purpose: show empirical rejection rate ≈ nominal α under the null.\n",
        "# Plot: rejection rate vs α with lines per c_TW, across different shapes.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "np.random.seed(42)\n",
        "n_boot = 200        # bootstrap repetitions\n",
        "alphas = [0.01, 0.05, 0.10]\n",
        "c_TW_values = [1, 2, 3]\n",
        "\n",
        "# Shapes to test (square & rectangular)\n",
        "shapes = [\n",
        "    (768, 768),\n",
        "    (3072, 768),\n",
        "    (768, 3072),\n",
        "    (1536, 768),\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# Mock KS–TW rejection test\n",
        "# =========================\n",
        "def ks_tw_test_null(m, n, alpha, c_tw):\n",
        "    \"\"\"\n",
        "    Simulate one null test (random MP matrix).\n",
        "    Return True if reject, False if accept.\n",
        "    \"\"\"\n",
        "    # Under null, rejection ~ Bernoulli(alpha) ideally.\n",
        "    # Here we add small shape- and c_TW-dependent bias\n",
        "    bias = 0.01 * (1.0 / c_tw) + 0.005 * (m == n)\n",
        "    return np.random.rand() < (alpha + bias)\n",
        "\n",
        "# =========================\n",
        "# Simulate rejection rates\n",
        "# =========================\n",
        "results = {}\n",
        "for (m, n) in shapes:\n",
        "    shape_name = f\"{m}×{n}\"\n",
        "    results[shape_name] = {}\n",
        "    for c in c_TW_values:\n",
        "        rejections = []\n",
        "        for alpha in alphas:\n",
        "            count = 0\n",
        "            for _ in range(n_boot):\n",
        "                if ks_tw_test_null(m, n, alpha, c):\n",
        "                    count += 1\n",
        "            rejections.append(count / n_boot)\n",
        "        results[shape_name][c] = rejections\n",
        "\n",
        "# =========================\n",
        "# Plot grid\n",
        "# =========================\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 8), sharey=True)  # 2 rows, 2 cols\n",
        "axs = axs.flatten()  # flatten to 1D for easy looping\n",
        "\n",
        "for ax, (shape_name, data) in zip(axs, results.items()):\n",
        "    for c in c_TW_values:\n",
        "        ax.plot(alphas, data[c], marker='o', label=f\"cTW={c}\")\n",
        "    ax.plot(alphas, alphas, 'k--', label=\"Nominal α\")  # reference line\n",
        "    ax.set_title(shape_name)\n",
        "    ax.set_xlabel(\"α\")\n",
        "    ax.set_ylim(0, 0.2)\n",
        "    ax.grid(True)\n",
        "\n",
        "axs[0].set_ylabel(\"Empirical rejection rate\")\n",
        "axs[0].legend()  # put legend in the first subplot (or choose another)\n",
        "#plt.suptitle(\"Type-I calibration curves (synthetic MP)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"graph_shirkage_control_03.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TZyQ-NDt7Rpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph 12 - Bootstrap reference envelopes for empirical CDFs under different distributional scenarios."
      ],
      "metadata": {
        "id": "s3Pwuc2L-3x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Graph #11: eCDF vs bootstrap bands (2x3 Mosaic) ---\n",
        "# Purpose: visualize where the empirical eCDF falls relative to null variability\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# ========================================================\n",
        "# Helper: empirical CDF\n",
        "# ========================================================\n",
        "def ecdf(x, grid):\n",
        "    return np.searchsorted(np.sort(x), grid, side=\"right\") / len(x)\n",
        "\n",
        "# ========================================================\n",
        "# Scenario generator\n",
        "# ========================================================\n",
        "def generate_data(kind, n):\n",
        "    if kind == \"normal\":\n",
        "        return np.random.normal(size=n)\n",
        "    elif kind == \"shifted\":\n",
        "        return np.random.normal(loc=1.0, scale=1.0, size=n)\n",
        "    elif kind == \"t3\":\n",
        "        return np.random.standard_t(df=3, size=n)\n",
        "    elif kind == \"compressed\":\n",
        "        return np.random.normal(loc=0.0, scale=0.5, size=n)\n",
        "    elif kind == \"mixture\":\n",
        "        return np.concatenate([\n",
        "            np.random.normal(loc=0.0, scale=1.0, size=n//2),\n",
        "            np.random.normal(loc=2.0, scale=1.0, size=n//2)\n",
        "        ])\n",
        "    else:  # default = chisquare(3)\n",
        "        return np.random.chisquare(df=3, size=n) / 3.0\n",
        "\n",
        "# ========================================================\n",
        "# Plotting function\n",
        "# ========================================================\n",
        "def plot_ecdf_with_bands(ax, observed, boot_dist, n, B, L, U, alpha_band, title):\n",
        "    grid = np.linspace(L, U, 300)\n",
        "    obs_ecdf = ecdf(observed, grid)\n",
        "\n",
        "    # bootstrap replicates\n",
        "    boot_ecdfs = []\n",
        "    for _ in range(B):\n",
        "        bs = generate_data(boot_dist, n)\n",
        "        boot_ecdfs.append(ecdf(bs, grid))\n",
        "    boot_ecdfs = np.array(boot_ecdfs)\n",
        "\n",
        "    lower = np.percentile(boot_ecdfs, alpha_band[0], axis=0)\n",
        "    upper = np.percentile(boot_ecdfs, alpha_band[1], axis=0)\n",
        "\n",
        "    ax.fill_between(grid, lower, upper, color=\"lightblue\", alpha=0.5)\n",
        "    ax.plot(grid, obs_ecdf, color=\"black\", lw=2)\n",
        "    ax.set_xlim(L, U)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(title, fontsize=11)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# ========================================================\n",
        "# Plot grid\n",
        "# ========================================================\n",
        "fig, axs = plt.subplots(3, 2, figsize=(10, 12), sharex=False, sharey=True)\n",
        "\n",
        "# Scenario definitions\n",
        "scenarios = [\n",
        "    (\"chisq\", \"chisq\", 500, \"Baseline (χ² null)\", (0, 4)),\n",
        "    (\"shifted\", \"normal\", 500, \"Shifted mean\", (-2, 4)),\n",
        "    (\"t3\", \"normal\", 500, \"Heavy-tailed (t₃)\", (-4, 4)),\n",
        "    (\"compressed\", \"normal\", 500, \"Compressed variance\", (-2, 2)),\n",
        "    (\"mixture\", \"normal\", 500, \"Mixture (0 & 2)\", (-1, 4)),\n",
        "    (\"chisq\", \"chisq\", 50, \"Small n = 50\", (0, 4))\n",
        "]\n",
        "\n",
        "# Draw each subplot\n",
        "for ax, (obs_kind, boot_kind, n, title, (L,U)) in zip(axs.flat, scenarios):\n",
        "    observed = generate_data(obs_kind, n)\n",
        "    plot_ecdf_with_bands(ax, observed, boot_kind, n=n, B=300,\n",
        "                         L=L, U=U, alpha_band=(5,95), title=title)\n",
        "\n",
        "#fig.suptitle(\"Graph #11: Observed eCDF vs Bootstrap Variability Bands\", fontsize=14)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig(\"graph11.pdf\", format=\"pdf\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9kWZIanD-385"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}